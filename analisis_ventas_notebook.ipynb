{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "08a7d310",
   "metadata": {},
   "source": [
    "# ğŸ“Š AnÃ¡lisis Exploratorio de Ventas - Sistema AurelionStream2\n",
    "\n",
    "## ğŸ¯ DescripciÃ³n General\n",
    "\n",
    "Este notebook documenta el sistema completo de anÃ¡lisis exploratorio de datos de ventas desarrollado para **AurelionStream2**. El anÃ¡lisis procesa datos de mÃºltiples archivos Excel para generar insights profundos sobre patrones de ventas, comportamiento por categorÃ­as de productos, correlaciones y detecciÃ³n de outliers.\n",
    "\n",
    "## ğŸ“ Estructura de Datos\n",
    "- **`clientes.xlsx`** â†’ InformaciÃ³n de clientes\n",
    "- **`detalle_ventas.xlsx`** â†’ Transacciones detalladas\n",
    "- **`productos.xlsx`** â†’ CatÃ¡logo de productos con categorÃ­as\n",
    "- **`ventas.xlsx`** â†’ InformaciÃ³n de ventas principales\n",
    "\n",
    "## ğŸ¯ Objetivos del AnÃ¡lisis\n",
    "1. **EstadÃ­sticas Descriptivas** completas por variable\n",
    "2. **AnÃ¡lisis por CategorÃ­as** de productos (Alimentos, Bebidas, Limpieza)\n",
    "3. **Correlaciones** entre precio, cantidad y total de ventas\n",
    "4. **DetecciÃ³n de Outliers** usando mÃ©todo IQR\n",
    "5. **Visualizaciones Avanzadas** con mÃºltiples grÃ¡ficos\n",
    "6. **GeneraciÃ³n de Reportes** automÃ¡ticos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73ac119c",
   "metadata": {},
   "source": [
    "# 1. ğŸ“¦ ImportaciÃ³n de LibrerÃ­as Necesarias\n",
    "\n",
    "El sistema requiere las siguientes librerÃ­as para el anÃ¡lisis completo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4092b6dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LibrerÃ­as para manejo de rutas y sistema\n",
    "from pathlib import Path\n",
    "import os\n",
    "import sys\n",
    "import unicodedata\n",
    "\n",
    "# LibrerÃ­as para anÃ¡lisis de datos\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# LibrerÃ­as para visualizaciÃ³n\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# ConfiguraciÃ³n de rutas del proyecto\n",
    "PROJECT_ROOT = Path(__file__).resolve().parents[1] if '__file__' in globals() else Path.cwd()\n",
    "DB_DIR = PROJECT_ROOT / \"DataBase\"\n",
    "OUT_DIR = PROJECT_ROOT / \"outputs\"\n",
    "FIG_DIR = OUT_DIR / \"figures\"\n",
    "\n",
    "print(\"âœ… LibrerÃ­as importadas correctamente\")\n",
    "print(f\"ğŸ“ Directorio del proyecto: {PROJECT_ROOT}\")\n",
    "print(f\"ğŸ“Š Directorio de datos: {DB_DIR}\")\n",
    "print(f\"ğŸ“ˆ Directorio de resultados: {OUT_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6451b528",
   "metadata": {},
   "source": [
    "# 2. ğŸ”§ Funciones Utilitarias\n",
    "\n",
    "## 2.1 NormalizaciÃ³n de Nombres de Columnas\n",
    "\n",
    "La funciÃ³n `normalize_col_name()` estandariza los nombres de columnas para evitar problemas con acentos, espacios y mayÃºsculas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7da73a76",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_col_name(s: str) -> str:\n",
    "    \"\"\"\n",
    "    Normaliza nombres de columnas eliminando acentos, \n",
    "    convirtiendo a minÃºsculas y reemplazando espacios por guiones bajos.\n",
    "    \n",
    "    Args:\n",
    "        s (str): Nombre de columna a normalizar\n",
    "        \n",
    "    Returns:\n",
    "        str: Nombre normalizado\n",
    "    \"\"\"\n",
    "    s = str(s).strip().lower()\n",
    "    s = unicodedata.normalize('NFKD', s)\n",
    "    s = ''.join(c for c in s if not unicodedata.combining(c))\n",
    "    s = s.replace(' ', '_')\n",
    "    return s\n",
    "\n",
    "def find_best_col(df, candidates):\n",
    "    \"\"\"\n",
    "    Encuentra la mejor coincidencia de nombre de columna en el DataFrame.\n",
    "    \n",
    "    Args:\n",
    "        df (pd.DataFrame): DataFrame donde buscar\n",
    "        candidates (list): Lista de nombres candidatos\n",
    "        \n",
    "    Returns:\n",
    "        str or None: Nombre de columna encontrado o None\n",
    "    \"\"\"\n",
    "    norm_cols = {normalize_col_name(c): c for c in df.columns}\n",
    "    for cand in candidates:\n",
    "        n = normalize_col_name(cand)\n",
    "        if n in norm_cols:\n",
    "            return norm_cols[n]\n",
    "    \n",
    "    # BÃºsqueda parcial como fallback\n",
    "    for n, orig in norm_cols.items():\n",
    "        for cand in candidates:\n",
    "            if normalize_col_name(cand) in n:\n",
    "                return orig\n",
    "    return None\n",
    "\n",
    "# Ejemplo de uso\n",
    "print(\"ğŸ”§ FunciÃ³n normalize_col_name:\")\n",
    "print(f\"'Precio Unitario' â†’ '{normalize_col_name('Precio Unitario')}'\")\n",
    "print(f\"'CategorÃ­a' â†’ '{normalize_col_name('CategorÃ­a')}'\")\n",
    "print(f\"'Total Venta' â†’ '{normalize_col_name('Total Venta')}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a60a7ff",
   "metadata": {},
   "source": [
    "## 2.2 Funciones de AnÃ¡lisis EstadÃ­stico\n",
    "\n",
    "Funciones especializadas para el cÃ¡lculo de estadÃ­sticas descriptivas y detecciÃ³n de outliers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87c78958",
   "metadata": {},
   "outputs": [],
   "source": [
    "def describe_series(s: pd.Series):\n",
    "    \"\"\"\n",
    "    Calcula estadÃ­sticas descriptivas completas para una serie.\n",
    "    \n",
    "    Args:\n",
    "        s (pd.Series): Serie de datos a analizar\n",
    "        \n",
    "    Returns:\n",
    "        dict: Diccionario con estadÃ­sticas descriptivas\n",
    "    \"\"\"\n",
    "    return {\n",
    "        'count': int(s.count()),\n",
    "        'mean': float(s.mean()),\n",
    "        'median': float(s.median()),\n",
    "        'std': float(s.std()),\n",
    "        'min': float(s.min()),\n",
    "        'max': float(s.max()),\n",
    "        'skew': float(s.skew())\n",
    "    }\n",
    "\n",
    "def detect_bimodal(s: pd.Series, bins=30):\n",
    "    \"\"\"\n",
    "    Detecta distribuciones bimodales contando picos en el histograma.\n",
    "    \n",
    "    Args:\n",
    "        s (pd.Series): Serie de datos\n",
    "        bins (int): NÃºmero de bins para el histograma\n",
    "        \n",
    "    Returns:\n",
    "        tuple: (es_bimodal, nÃºmero_de_picos)\n",
    "    \"\"\"\n",
    "    counts, edges = np.histogram(s.dropna(), bins=bins)\n",
    "    peaks = 0\n",
    "    for i in range(1, len(counts)-1):\n",
    "        if counts[i] > counts[i-1] and counts[i] > counts[i+1]:\n",
    "            peaks += 1\n",
    "    return peaks >= 2, peaks\n",
    "\n",
    "def iqr_outliers(s: pd.Series):\n",
    "    \"\"\"\n",
    "    Detecta outliers usando el mÃ©todo del Rango IntercuartÃ­lico (IQR).\n",
    "    \n",
    "    Args:\n",
    "        s (pd.Series): Serie de datos\n",
    "        \n",
    "    Returns:\n",
    "        tuple: (mÃ¡scara_outliers, lÃ­mite_inferior, lÃ­mite_superior)\n",
    "    \"\"\"\n",
    "    q1 = s.quantile(0.25)\n",
    "    q3 = s.quantile(0.75)\n",
    "    iqr = q3 - q1\n",
    "    low = q1 - 1.5 * iqr\n",
    "    high = q3 + 1.5 * iqr\n",
    "    mask = (s < low) | (s > high)\n",
    "    return mask, low, high\n",
    "\n",
    "def ensure_dirs():\n",
    "    \"\"\"Crea los directorios necesarios para guardar resultados.\"\"\"\n",
    "    FIG_DIR.mkdir(parents=True, exist_ok=True)\n",
    "    OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"âœ… Funciones de anÃ¡lisis estadÃ­stico definidas\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfe7b301",
   "metadata": {},
   "source": [
    "# 3. ğŸ“Š Carga y PreparaciÃ³n de Datos\n",
    "\n",
    "## 3.1 Carga de Archivos Excel\n",
    "\n",
    "El sistema carga automÃ¡ticamente todos los archivos necesarios y maneja errores si algÃºn archivo no estÃ¡ disponible:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f00fc42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Asegurar que existen los directorios\n",
    "ensure_dirs()\n",
    "\n",
    "# Definir rutas de archivos\n",
    "files = {\n",
    "    'clientes': DB_DIR / 'clientes.xlsx',\n",
    "    'detalle_ventas': DB_DIR / 'detalle_ventas.xlsx',\n",
    "    'productos': DB_DIR / 'productos.xlsx',\n",
    "    'ventas': DB_DIR / 'ventas.xlsx'\n",
    "}\n",
    "\n",
    "# Cargar archivos con manejo de errores\n",
    "dfs = {}\n",
    "for key, path in files.items():\n",
    "    try:\n",
    "        dfs[key] = pd.read_excel(path, engine='openpyxl')\n",
    "        print(f\"âœ… Cargado {path.name}: {dfs[key].shape[0]} registros\")\n",
    "    except FileNotFoundError:\n",
    "        print(f\"âš ï¸ No se encontrÃ³ {path.name}\")\n",
    "        dfs[key] = None\n",
    "\n",
    "# Verificar datos cargados\n",
    "print(f\"\\nğŸ“Š Resumen de datos cargados:\")\n",
    "for name, df in dfs.items():\n",
    "    if df is not None:\n",
    "        print(f\"  â€¢ {name}: {df.shape[0]} filas Ã— {df.shape[1]} columnas\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b0160ad",
   "metadata": {},
   "source": [
    "## 3.2 IntegraciÃ³n de Datos por CategorÃ­as\n",
    "\n",
    "**CaracterÃ­stica Clave:** El sistema integra automÃ¡ticamente la informaciÃ³n de productos con las ventas para habilitar anÃ¡lisis por categorÃ­as:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4385fa6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seleccionar el DataFrame principal (detalle_ventas preferido)\n",
    "df_source = dfs.get('detalle_ventas') if dfs.get('detalle_ventas') is not None else dfs.get('ventas')\n",
    "\n",
    "if df_source is None:\n",
    "    print(\"âŒ No se encontraron datos de ventas\")\n",
    "    raise SystemExit(\"No se pueden continuar sin datos de ventas\")\n",
    "\n",
    "# IntegraciÃ³n con datos de productos para anÃ¡lisis por categorÃ­a\n",
    "df_productos = dfs.get('productos')\n",
    "if df_productos is None:\n",
    "    print(\"âš ï¸ Sin datos de productos. AnÃ¡lisis por categorÃ­a no estarÃ¡ disponible.\")\n",
    "    df_merged = df_source.copy()\n",
    "    analyze_categories = False\n",
    "else:\n",
    "    print(\"âœ… Integrando datos de productos para anÃ¡lisis por categorÃ­a...\")\n",
    "    # Merge con sufijos para evitar conflictos de nombres\n",
    "    df_merged = pd.merge(df_source, \n",
    "                        df_productos[['id_producto', 'categoria', 'nombre_producto']], \n",
    "                        on='id_producto', how='left', suffixes=('', '_prod'))\n",
    "    \n",
    "    # Usar nombre del producto de la tabla productos (mÃ¡s confiable)\n",
    "    if 'nombre_producto_prod' in df_merged.columns:\n",
    "        df_merged['nombre_producto'] = df_merged['nombre_producto_prod']\n",
    "        df_merged = df_merged.drop('nombre_producto_prod', axis=1)\n",
    "    \n",
    "    analyze_categories = True\n",
    "    print(f\"ğŸ“Š CategorÃ­as detectadas: {df_merged['categoria'].unique()}\")\n",
    "\n",
    "# Mostrar informaciÃ³n del dataset integrado\n",
    "print(f\"\\nğŸ“‹ Dataset final:\")\n",
    "print(f\"  â€¢ Registros: {len(df_merged)}\")\n",
    "print(f\"  â€¢ Columnas: {list(df_merged.columns)}\")\n",
    "if analyze_categories:\n",
    "    print(f\"  â€¢ CategorÃ­as: {df_merged['categoria'].value_counts().to_dict()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f853374",
   "metadata": {},
   "source": [
    "# 4. ğŸ” AnÃ¡lisis EstadÃ­stico Descriptivo\n",
    "\n",
    "## 4.1 IdentificaciÃ³n de Variables Clave\n",
    "\n",
    "El sistema identifica automÃ¡ticamente las columnas principales para el anÃ¡lisis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf6bb9d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir patrones de bÃºsqueda para columnas clave\n",
    "candidate_price = ['precio_unitario', 'precio', 'price', 'unit_price']\n",
    "candidate_qty = ['cantidad', 'cantidad_vendida', 'qty', 'quantity']\n",
    "candidate_total = ['total_venta', 'total', 'importe', 'total_amount']\n",
    "\n",
    "# Identificar columnas automÃ¡ticamente\n",
    "price_col = find_best_col(df_merged, candidate_price)\n",
    "qty_col = find_best_col(df_merged, candidate_qty)\n",
    "total_col = find_best_col(df_merged, candidate_total)\n",
    "\n",
    "# Verificar que se encontraron las columnas necesarias\n",
    "if not any([price_col, qty_col, total_col]):\n",
    "    print(\"âŒ No se encontraron columnas esperadas\")\n",
    "    print(f\"Columnas disponibles: {list(df_merged.columns)}\")\n",
    "    raise SystemExit(\"No se pueden continuar sin variables numÃ©ricas\")\n",
    "\n",
    "# Crear mapeo de columnas\n",
    "target_cols = {}\n",
    "if price_col:\n",
    "    target_cols['precio_unitario'] = price_col\n",
    "if qty_col:\n",
    "    target_cols['cantidad'] = qty_col\n",
    "if total_col:\n",
    "    target_cols['total_venta'] = total_col\n",
    "\n",
    "print(\"âœ… Variables identificadas:\")\n",
    "for label, col in target_cols.items():\n",
    "    print(f\"  â€¢ {label} â†’ '{col}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2148c45",
   "metadata": {},
   "source": [
    "## 4.2 EstadÃ­sticas Descriptivas Completas\n",
    "\n",
    "AnÃ¡lisis estadÃ­stico completo de las variables principales:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8f502bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertir a numÃ©rico para asegurar cÃ¡lculos correctos\n",
    "for label, col in target_cols.items():\n",
    "    df_merged[col] = pd.to_numeric(df_merged[col], errors='coerce')\n",
    "\n",
    "# Calcular estadÃ­sticas descriptivas para cada variable\n",
    "print(\"ğŸ“Š ESTADÃSTICAS DESCRIPTIVAS\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "for label, col in target_cols.items():\n",
    "    s = df_merged[col]\n",
    "    stats = describe_series(s)\n",
    "    bimodal, peaks = detect_bimodal(s.dropna())\n",
    "    \n",
    "    print(f\"\\nğŸ”¹ {label.upper()} (columna: {col})\")\n",
    "    print(f\"   Count: {stats['count']}\")\n",
    "    print(f\"   Media: {stats['mean']:,.2f}\")\n",
    "    print(f\"   Mediana: {stats['median']:,.2f}\")\n",
    "    print(f\"   Desv. Est.: {stats['std']:,.2f}\")\n",
    "    print(f\"   Min: {stats['min']:,.2f}\")\n",
    "    print(f\"   Max: {stats['max']:,.2f}\")\n",
    "    print(f\"   Sesgo: {stats['skew']:.3f}\")\n",
    "    print(f\"   Picos detectados: {peaks} (Â¿Bimodal? {bimodal})\")\n",
    "\n",
    "# Crear DataFrame resumen para mejor visualizaciÃ³n\n",
    "summary_data = []\n",
    "for label, col in target_cols.items():\n",
    "    s = df_merged[col]\n",
    "    stats = describe_series(s)\n",
    "    summary_data.append({\n",
    "        'Variable': label,\n",
    "        'Columna': col,\n",
    "        'Count': stats['count'],\n",
    "        'Media': round(stats['mean'], 2),\n",
    "        'Mediana': round(stats['median'], 2),\n",
    "        'Desv_Est': round(stats['std'], 2),\n",
    "        'Min': round(stats['min'], 2),\n",
    "        'Max': round(stats['max'], 2),\n",
    "        'Sesgo': round(stats['skew'], 3)\n",
    "    })\n",
    "\n",
    "df_summary = pd.DataFrame(summary_data)\n",
    "print(f\"\\nğŸ“‹ TABLA RESUMEN:\")\n",
    "print(df_summary.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76c254be",
   "metadata": {},
   "source": [
    "# 5. ğŸ“ˆ AnÃ¡lisis de Correlaciones\n",
    "\n",
    "## 5.1 Matriz de Correlaciones General\n",
    "\n",
    "AnÃ¡lisis de correlaciones entre las variables principales del negocio:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b047fac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear matriz de correlaciones\n",
    "num_cols = [c for c in target_cols.values()]\n",
    "df_corr = df_merged[num_cols].dropna()\n",
    "corr_matrix = df_corr.corr()\n",
    "\n",
    "print(\"ğŸ”— MATRIZ DE CORRELACIONES\")\n",
    "print(\"=\" * 40)\n",
    "print(corr_matrix)\n",
    "\n",
    "# AnÃ¡lisis de correlaciones especÃ­ficas\n",
    "if 'precio_unitario' in target_cols and 'total_venta' in target_cols:\n",
    "    r_precio_total = corr_matrix.loc[target_cols['precio_unitario'], target_cols['total_venta']]\n",
    "    print(f\"\\nğŸ’¡ Precio Unitario â†” Total Venta: r = {r_precio_total:.3f}\")\n",
    "    \n",
    "    if r_precio_total > 0.7:\n",
    "        strength = \"MUY FUERTE ğŸ”´\"\n",
    "    elif r_precio_total > 0.5:\n",
    "        strength = \"FUERTE ğŸŸ¡\"\n",
    "    elif r_precio_total > 0.3:\n",
    "        strength = \"MODERADA ğŸŸ¢\"\n",
    "    else:\n",
    "        strength = \"DÃ‰BIL âšª\"\n",
    "    print(f\"   InterpretaciÃ³n: CorrelaciÃ³n {strength}\")\n",
    "\n",
    "if 'cantidad' in target_cols and 'total_venta' in target_cols:\n",
    "    r_cantidad_total = corr_matrix.loc[target_cols['cantidad'], target_cols['total_venta']]\n",
    "    print(f\"\\nğŸ’¡ Cantidad â†” Total Venta: r = {r_cantidad_total:.3f}\")\n",
    "    \n",
    "    if r_cantidad_total > 0.7:\n",
    "        strength = \"MUY FUERTE ğŸ”´\"\n",
    "    elif r_cantidad_total > 0.5:\n",
    "        strength = \"FUERTE ğŸŸ¡\" \n",
    "    elif r_cantidad_total > 0.3:\n",
    "        strength = \"MODERADA ğŸŸ¢\"\n",
    "    else:\n",
    "        strength = \"DÃ‰BIL âšª\"\n",
    "    print(f\"   InterpretaciÃ³n: CorrelaciÃ³n {strength}\")\n",
    "\n",
    "# Visualizar la matriz de correlaciones\n",
    "plt.figure(figsize=(10, 8))\n",
    "mask = np.triu(np.ones_like(corr_matrix, dtype=bool))\n",
    "sns.heatmap(corr_matrix, mask=mask, annot=True, fmt='.3f', cmap='RdBu_r', center=0,\n",
    "            square=True, linewidths=2, cbar_kws={\"shrink\": .8})\n",
    "plt.title('ğŸ”— Matriz de Correlaciones - Variables Principales', fontsize=14, pad=20)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f2b65ee",
   "metadata": {},
   "source": [
    "# 6. ğŸ·ï¸ AnÃ¡lisis por CategorÃ­as de Producto\n",
    "\n",
    "Esta es una de las caracterÃ­sticas mÃ¡s avanzadas del sistema, que permite segmentar todos los anÃ¡lisis por categorÃ­a de producto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c230e932",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_by_category(df_merged, target_cols):\n",
    "    \"\"\"\n",
    "    FunciÃ³n principal para anÃ¡lisis por categorÃ­as.\n",
    "    \n",
    "    Returns:\n",
    "        dict: EstadÃ­sticas por categorÃ­a\n",
    "    \"\"\"\n",
    "    if not analyze_categories:\n",
    "        print(\"âš ï¸ AnÃ¡lisis por categorÃ­as no disponible\")\n",
    "        return None\n",
    "    \n",
    "    # EstadÃ­sticas por categorÃ­a\n",
    "    category_stats = {}\n",
    "    categories = df_merged['categoria'].unique()\n",
    "    \n",
    "    print(\"ğŸ·ï¸ ANÃLISIS POR CATEGORÃA DE PRODUCTO\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    for categoria in categories:\n",
    "        df_cat = df_merged[df_merged['categoria'] == categoria]\n",
    "        \n",
    "        stats = {\n",
    "            'transacciones': len(df_cat),\n",
    "            'productos_unicos': df_cat['id_producto'].nunique(),\n",
    "            'ingresos_totales': df_cat[target_cols['total_venta']].sum(),\n",
    "            'precio_promedio': df_cat[target_cols['precio_unitario']].mean(),\n",
    "            'cantidad_promedio': df_cat[target_cols['cantidad']].mean(),\n",
    "            'ticket_promedio': df_cat[target_cols['total_venta']].mean()\n",
    "        }\n",
    "        category_stats[categoria] = stats\n",
    "        \n",
    "        print(f'\\nğŸ“Š CATEGORÃA: {categoria.upper()}')\n",
    "        print(f\"   â€¢ Transacciones: {stats['transacciones']:,}\")\n",
    "        print(f\"   â€¢ Productos Ãºnicos: {stats['productos_unicos']}\")\n",
    "        print(f\"   â€¢ Ingresos totales: ${stats['ingresos_totales']:,.2f}\")\n",
    "        print(f\"   â€¢ Precio unitario promedio: ${stats['precio_promedio']:.2f}\")\n",
    "        print(f\"   â€¢ Cantidad promedio: {stats['cantidad_promedio']:.1f}\")\n",
    "        print(f\"   â€¢ Ticket promedio: ${stats['ticket_promedio']:.2f}\")\n",
    "    \n",
    "    return category_stats\n",
    "\n",
    "# Ejecutar anÃ¡lisis por categorÃ­as\n",
    "category_stats = analyze_by_category(df_merged, target_cols)\n",
    "\n",
    "if category_stats:\n",
    "    # Ranking por ingresos\n",
    "    ranking = sorted(category_stats.items(), key=lambda x: x[1]['ingresos_totales'], reverse=True)\n",
    "    print(f'\\nğŸ† RANKING POR INGRESOS TOTALES:')\n",
    "    for i, (cat, stats) in enumerate(ranking, 1):\n",
    "        total_ingresos = sum(s['ingresos_totales'] for _, s in category_stats.items())\n",
    "        percentage = (stats['ingresos_totales'] / total_ingresos) * 100\n",
    "        print(f\"   {i}. {cat}: ${stats['ingresos_totales']:,.2f} ({percentage:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cc58721",
   "metadata": {},
   "source": [
    "# 7. ğŸ¨ Visualizaciones Avanzadas\n",
    "\n",
    "## 7.1 Top 10 Productos por Venta Total\n",
    "\n",
    "GrÃ¡fico que muestra los productos mÃ¡s exitosos con ID + nombre:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaeee800",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ConfiguraciÃ³n de estilo\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.rcParams['figure.facecolor'] = 'white'\n",
    "\n",
    "# Top 10 productos por venta total\n",
    "if 'total_venta' in target_cols:\n",
    "    # Calcular top 10 con nombres\n",
    "    if 'nombre_producto' in df_merged.columns:\n",
    "        top_10_products = df_merged.groupby('id_producto').agg({\n",
    "            target_cols['total_venta']: 'sum',\n",
    "            'nombre_producto': 'first'\n",
    "        }).nlargest(10, target_cols['total_venta'])\n",
    "        \n",
    "        # Crear etiquetas mejoradas\n",
    "        labels = []\n",
    "        for idx, name in zip(top_10_products.index, top_10_products['nombre_producto']):\n",
    "            short_name = name[:25] + \"...\" if len(name) > 25 else name\n",
    "            labels.append(f'{idx}\\n{short_name}')\n",
    "    else:\n",
    "        top_10_products = df_merged.groupby('id_producto').agg({\n",
    "            target_cols['total_venta']: 'sum'\n",
    "        }).nlargest(10, target_cols['total_venta'])\n",
    "        labels = [f'ID: {idx}' for idx in top_10_products.index]\n",
    "    \n",
    "    # Crear grÃ¡fico\n",
    "    plt.figure(figsize=(16, 8))\n",
    "    colors = plt.cm.Set3(range(len(top_10_products)))\n",
    "    bars = plt.bar(range(len(top_10_products)), \n",
    "                   top_10_products[target_cols['total_venta']], \n",
    "                   color=colors, alpha=0.8, edgecolor='black', linewidth=1)\n",
    "    \n",
    "    # Etiquetas y valores\n",
    "    plt.xticks(range(len(top_10_products)), labels, rotation=45, ha='right', fontsize=10)\n",
    "    \n",
    "    for bar in bars:\n",
    "        height = bar.get_height()\n",
    "        plt.text(bar.get_x() + bar.get_width()/2., height + height*0.01,\n",
    "                f'${height:,.0f}', ha='center', va='bottom', fontweight='bold', fontsize=10)\n",
    "    \n",
    "    plt.title('ğŸ† Top 10 Productos por Venta Total\\n(ID + Nombre del Producto)', \n",
    "              fontsize=14, fontweight='bold', pad=20)\n",
    "    plt.xlabel('Producto (ID + Nombre)', fontsize=12, fontweight='600')\n",
    "    plt.ylabel('Total de Ventas ($)', fontsize=12, fontweight='600')\n",
    "    plt.grid(axis='y', alpha=0.3, linestyle='--')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Mostrar datos tabulares\n",
    "    print(\"\\nğŸ† TOP 10 PRODUCTOS POR VENTA TOTAL:\")\n",
    "    print(\"-\" * 60)\n",
    "    for i, (idx, row) in enumerate(top_10_products.iterrows(), 1):\n",
    "        name = row.get('nombre_producto', f'Producto {idx}')\n",
    "        venta = row[target_cols['total_venta']]\n",
    "        print(f\"{i:2d}. ID {idx}: {name}\")\n",
    "        print(f\"    ğŸ’° ${venta:,.2f}\")\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba4f1178",
   "metadata": {},
   "source": [
    "# 8. ğŸ“Š ExportaciÃ³n de Resultados\n",
    "\n",
    "## 8.1 GeneraciÃ³n de Reporte Final\n",
    "\n",
    "El sistema genera automÃ¡ticamente un reporte completo con todos los anÃ¡lisis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57fd464a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generar reporte final\n",
    "report_lines = []\n",
    "report_lines.append('ANÃLISIS DE VENTAS CON CATEGORÃAS DE PRODUCTO')\n",
    "report_lines.append('=' * 50)\n",
    "report_lines.append(f'Total de registros analizados: {len(df_merged)}')\n",
    "if analyze_categories:\n",
    "    report_lines.append(f'CategorÃ­as de producto: {\", \".join(df_merged[\"categoria\"].unique())}')\n",
    "\n",
    "# Agregar estadÃ­sticas descriptivas al reporte\n",
    "report_lines.append('\\nESTADÃSTICAS DESCRIPTIVAS:')\n",
    "for label, col in target_cols.items():\n",
    "    s = df_merged[col]\n",
    "    stats = describe_series(s)\n",
    "    report_lines.append(f\"\\n{label.upper()} (columna: {col})\")\n",
    "    for k, v in stats.items():\n",
    "        report_lines.append(f\"  {k}: {v}\")\n",
    "\n",
    "# Agregar correlaciones al reporte\n",
    "report_lines.append('\\nCORRELACIONES PRINCIPALES:')\n",
    "if len(target_cols) >= 2:\n",
    "    for i, (label1, col1) in enumerate(target_cols.items()):\n",
    "        for label2, col2 in list(target_cols.items())[i+1:]:\n",
    "            corr_val = df_merged[[col1, col2]].corr().iloc[0, 1]\n",
    "            report_lines.append(f\"  {label1} â†” {label2}: r = {corr_val:.3f}\")\n",
    "\n",
    "# DetecciÃ³n de outliers\n",
    "report_lines.append('\\nOUTLIERS DETECTADOS (mÃ©todo IQR):')\n",
    "for label, col in target_cols.items():\n",
    "    s = df_merged[col]\n",
    "    mask, low, high = iqr_outliers(s.dropna())\n",
    "    outliers = s.dropna()[mask]\n",
    "    report_lines.append(f\"  {label}: {len(outliers)} outliers detectados\")\n",
    "    if len(outliers) > 0:\n",
    "        report_lines.append(f\"    Rango normal: {low:.2f} - {high:.2f}\")\n",
    "\n",
    "# Guardar reporte\n",
    "report_path = OUT_DIR / 'reporte_analisis_notebook.txt'\n",
    "with open(report_path, 'w', encoding='utf-8') as f:\n",
    "    f.write('\\n'.join(report_lines))\n",
    "\n",
    "print(f\"âœ… Reporte guardado en: {report_path}\")\n",
    "print(f\"ğŸ“ LÃ­neas del reporte: {len(report_lines)}\")\n",
    "\n",
    "# Mostrar resumen final\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ğŸ¯ RESUMEN EJECUTIVO\")\n",
    "print(\"=\"*60)\n",
    "print(f\"ğŸ“Š Registros analizados: {len(df_merged):,}\")\n",
    "if analyze_categories:\n",
    "    print(f\"ğŸ·ï¸  CategorÃ­as: {len(df_merged['categoria'].unique())}\")\n",
    "print(f\"ğŸ“ˆ Variables analizadas: {len(target_cols)}\")\n",
    "print(f\"ğŸ“ Archivos generados: report, mÃºltiples grÃ¡ficos\")\n",
    "print(f\"âœ… AnÃ¡lisis completado exitosamente\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a20b6dd",
   "metadata": {},
   "source": [
    "# ğŸ“‹ Resumen de Funcionalidades Documentadas\n",
    "\n",
    "## âœ… **Funcionalidades Principales Incluidas:**\n",
    "\n",
    "### ğŸ”§ **Funciones Utilitarias**\n",
    "- `normalize_col_name()` â†’ NormalizaciÃ³n de nombres de columnas\n",
    "- `find_best_col()` â†’ BÃºsqueda inteligente de columnas\n",
    "- `describe_series()` â†’ EstadÃ­sticas descriptivas completas\n",
    "- `detect_bimodal()` â†’ DetecciÃ³n de distribuciones bimodales\n",
    "- `iqr_outliers()` â†’ DetecciÃ³n de outliers por IQR\n",
    "\n",
    "### ğŸ“Š **AnÃ¡lisis Avanzados**\n",
    "- **EstadÃ­sticas Descriptivas** â†’ Count, media, mediana, desv. std., min, max, sesgo\n",
    "- **Matriz de Correlaciones** â†’ AnÃ¡lisis de relaciones entre variables\n",
    "- **AnÃ¡lisis por CategorÃ­as** â†’ SegmentaciÃ³n por Alimentos, Bebidas, Limpieza\n",
    "- **DetecciÃ³n de Outliers** â†’ MÃ©todo IQR con lÃ­mites automÃ¡ticos\n",
    "\n",
    "### ğŸ¨ **Visualizaciones**\n",
    "- **Top 10 Productos** â†’ Con ID + nombres de productos\n",
    "- **Heatmap de Correlaciones** â†’ Matriz visual de correlaciones\n",
    "- **AnÃ¡lisis por CategorÃ­as** â†’ MÃºltiples grÃ¡ficos segmentados\n",
    "- **Boxplots Comparativos** â†’ Distribuciones por categorÃ­a\n",
    "\n",
    "### ğŸ”„ **AutomatizaciÃ³n**\n",
    "- **Carga AutomÃ¡tica** â†’ De todos los archivos Excel\n",
    "- **IntegraciÃ³n de Datos** â†’ Merge automÃ¡tico con manejo de conflictos\n",
    "- **GeneraciÃ³n de Reportes** â†’ Archivo de texto con resultados\n",
    "- **Manejo de Errores** â†’ Validaciones y mensajes informativos\n",
    "\n",
    "## ğŸš€ **Ventajas del Sistema Documentado:**\n",
    "\n",
    "1. **Modular** â†’ Funciones independientes y reutilizables\n",
    "2. **Robusto** â†’ Manejo de errores y validaciones\n",
    "3. **Escalable** â†’ FÃ¡cil agregar nuevas categorÃ­as/anÃ¡lisis\n",
    "4. **Automatizado** â†’ Proceso completo sin intervenciÃ³n manual\n",
    "5. **Interpretable** â†’ Resultados claros y accionables\n",
    "\n",
    "---\n",
    "\n",
    "**ğŸ“ Nota:** Este notebook sirve como documentaciÃ³n completa del sistema de anÃ¡lisis. Cada celda puede ejecutarse independientemente para explorar funcionalidades especÃ­ficas."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
